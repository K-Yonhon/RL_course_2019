{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL interface\n",
    "\n",
    "## Goal:\n",
    "\n",
    "- Familiarize yourself with the programming interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import chula_rl as rl\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    # define the environment here we use Gridworld\n",
    "    env = rl.env.Gridworld(shape=(4, 3),\n",
    "                           start=(2, 0),\n",
    "                           goal=(1, 2),\n",
    "                           move_reward=-1)\n",
    "    env = rl.env.wrapper.ClipEpisodeLength(env, n_max_length=10)\n",
    "    env = rl.env.wrapper.EpisodeSummary(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is our gridword environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env()\n",
    "env.reset()\n",
    "env.render()\n",
    "print('Map: -1 = trap, 1 = goal, 2 = current')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You start at (2, 0) the goal is at (1, 2) where exists the reward of 5. \n",
    "\n",
    "There is no penalty of hitting the wall, you'll just bounce off it.\n",
    "\n",
    "### Possible actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('kind of action space:', env.action_space)\n",
    "print('number of possible actions:', env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just select a number 0-3 then.\n",
    "\n",
    "Here:\n",
    "- 0 = up\n",
    "- 1 = left\n",
    "- 2 = down\n",
    "- 3 = right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running in the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()\n",
    "env.render()\n",
    "print('current state:', s)\n",
    "s, r, done, info = env.step(0) # up\n",
    "env.render()\n",
    "print('current state:', s, '| reward:', r, '| is done:', done)\n",
    "s, r, done, info = env.step(0) # up\n",
    "env.render()\n",
    "print('current state:', s, '| reward:', r, '| is done:', done)\n",
    "s, r, done, info = env.step(0) # up, you won't move anywhere (but still recieve -1 reward)\n",
    "env.render()\n",
    "print('current state:', s, '| reward:', r, '| is done:', done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward -1 for every move is a way to force you to be fast.\n",
    "\n",
    "### If we reach a trap we get a negative reward, if we reach a goal we get a positive reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()\n",
    "env.render()\n",
    "print('current state:', s)\n",
    "s, r, done, info = env.step(3) # right\n",
    "env.render()\n",
    "print('current state:', s, '| reward:', r, '| is done:', done)\n",
    "s, r, done, info = env.step(0) # up, fallen into the pit (-5 reward)\n",
    "env.render()\n",
    "print('current state:', s, '| reward:', r, '| is done:', done)\n",
    "s, r, done, info = env.step(3) # right, reached the goal state, receiving (5 reward)\n",
    "env.render()\n",
    "print('current state:', s, '| reward:', r, '| is done:', done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An optimal path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()\n",
    "env.render()\n",
    "print('current state:', s)\n",
    "s, r, done, info = env.step(3) # right\n",
    "env.render()\n",
    "print('current state:', s, '| reward:', r, '| is done:', done)\n",
    "s, r, done, info = env.step(3) # right\n",
    "env.render()\n",
    "print('current state:', s, '| reward:', r, '| is done:', done)\n",
    "s, r, done, info = env.step(0) # up, reached the goal state, receiving reward of 5 (also -1)\n",
    "env.render()\n",
    "print('current state:', s, '| reward:', r, '| is done:', done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`action_space` has a `sample()` method for uniform sampling an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run many steps until termination (either reaching the goal, or being clipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()\n",
    "while True:\n",
    "    a = env.action_space.sample()\n",
    "    s, r, done, info = env.step(a)\n",
    "    if done: # episode ends\n",
    "        print(info) # summary of the episode\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "Create a new cell below each question to type in the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Why do we want to clip the episode length?\n",
    "\n",
    "Describe here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: What is an average epsiode length without clipping?\n",
    "Hint: conduct an experiment to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
